# File: run_mom.sh.in
# Purpose: input for BASH script for running MOM5 models
# Author: Vassili Kitsios, modified from previous script of Pavel Sakov
# Date: 2020

set -euxEo pipefail
ulimit -c unlimited
export F_UFMTENDIAN=big

module list

#-------------------------------------------
# Change the <DT> variable if need to reduce timestep due to numerical instability.
DT=DT_INPUT  
# Shorten the <months> variable if <DT> wass made smaller due to numerical instability 
# and run time for full forecast too long to fit into maximim walltime.
# Esnure that <months> is an integer multiple of <months_orig> so that the <NUM_CYCLES> variables is also an integer.
months=MONTHS_INPUT
#-------------------------------------------

WDIR=WDIR_INPUT
SAVE_EXP_DIR=SAVE_EXP_DIR_INPUT
CYCLE_ID=CYCLE_ID_INPUT
mem=MEM1_INPUT
months_orig=MONTHS_INPUT
DT_orig=DT_INPUT
NUM_CYCLES=$((months_orig / months))

PYTHON=PYTHON_INPUT
POSTPROCESSING_SRCDIR=POSTPROCESSING_SRCDIR_INPUT
POSTPROCESSING_LOGDIR=POSTPROCESSING_LOGDIR_INPUT
ZARR_PATH=ZARR_PATH_INPUT
ZARR_CONFIG_FILE=zarr_specs_CAFE-f6.json
ZARR_OUTPUT_PATH=${SAVE_EXP_DIR}/ZARR
GITHUB_MESSAGE_DIR=${WDIR}/github_messages
CHECK_CONFIG_FILE=check_specs.json

JULDAY=`cat ${WDIR}/JULDAY.txt | head -1`
EXPNAME=`basename ${WDIR}`
memstr=`printf "mem%03d" $mem`

# Make status logging directories
mkdir -p $GITHUB_MESSAGE_DIR
mkdir -p $POSTPROCESSING_LOGDIR


#====================================================================
# Small wrapper to make messaging simpler
github_message(){

        # Get user-provided stage and status information
        stage=$1
        status=$2

        # Execute
        python $POSTPROCESSING_SRCDIR/message.py \
        $GITHUB_MESSAGE_DIR \
        $EXPNAME/$memstr \
        $WDIR \
        $stage \
        $status

        # TODO: Provide a -m (message) option for errors?
}

cd ${WDIR}/$memstr

#====================================================================
# Check previous failures have been cleaned up
#-------------------------------------------
# NOTE: Need .failed files for REGRID_${memstr}, ZARR_${memstr}, MERGE_${realm}
#-------------------------------------------
for prefix in MOM NETCDF_COMBINE CHECK; do
	if [ -f "${POSTPROCESSING_LOGDIR}/${prefix}_${memstr}.failed" ]; then
		echo Clean up $prefix for member $mem
		exit
	fi
done

for prefix in CHECK_MERGE; do
	if [ -f "${POSTPROCESSING_LOGDIR}/${prefix}.failed" ]; then
		echo Clean up $prefix
		exit
	fi
done

if [ -f ${WDIR}/STOP ] || [ -f ${WDIR}/STOP_${memstr} ] ; then
    echo "STOP file detected, terminating"
    exit 0
fi


#====================================================================
if [ ! -f "${POSTPROCESSING_LOGDIR}/MOM_${memstr}.done" ]; then
	# Build namelist
	set +e
	rm -f input.nml

	if [ -f ${POSTPROCESSING_LOGDIR}/MOM_${memstr}.progress ] ; then
		CYCLE_ID=`cat ${POSTPROCESSING_LOGDIR}/MOM_${memstr}.progress | head -1`
	else
		CYCLE_ID=0
	fi

        if (( CYCLE_ID == 0 )) ; then
		# first MOM cycle
	       	THUMP=.true.
        else
		# restart from previous MOM cycle if needed to split into two jobs
	       	THUMP=.false.
        fi

	cat ${WDIR}/MOM/input.nml \
		| sed "s/.*dt_ocean.*/dt_ocean = ${DT}/"\
	       	| sed "s/.*dt_cpld.*/dt_cpld = ${DT}/"\
	       	| sed "s/.*dt_atmos.*/dt_atmos = ${DT}/"\
		| sed "s/INPUT_MONTHS/months = ${months}/"\
		| sed "s/USE_HARD_THUMP/use_hard_thump=${THUMP}/"\
	       	> input.nml

	# Launch MOM job
	github_message forecast start
	MOM_COMMAND_INPUT ./EXEC  2>&1 | tee mom-${DT}.out

	# Checck for successful completion
	set -e
        mom_complete_flag=`tail -n1 mom-${DT}.out | grep 'MPP_STACK high water mark=' | grep '0' | wc -l`
        if (( mom_complete_flag == 1 )) ; then
                echo "mom job complete"

                # backup input files
                mkdir -p INPUT_SAVE
                files=`ls INPUT/*.res.nc*`
                for file in $files ; do
                        if [ -f "$file" ] ; then
                                mv $file INPUT_SAVE
                        fi
                done
                mv -f RESTART/* INPUT
                rm -f INPUT/????????.??0000.*.nc
                rm -f INPUT/????????.??0000.*.res

		if (( months_orig == months )) ; then
	                touch ${POSTPROCESSING_LOGDIR}/MOM_${memstr}.done
			github_message forecast success
		else
			(( CYCLE_ID += 1 ))
        		if (( NUM_CYCLES == CYCLE_ID )) ; then
				rm ${POSTPROCESSING_LOGDIR}/MOM_${memstr}.progress
	                	touch ${POSTPROCESSING_LOGDIR}/MOM_${memstr}.done
				github_message forecast success
			else
				# number of months in forecast has changed presumably due to reduced timestep size
				echo ${CYCLE_ID} > ${POSTPROCESSING_LOGDIR}/MOM_${memstr}.progress
				echo "mom-${CYCLE_ID}-MOM (member $mem) in progress and requires user verification and then relaunch, bailing out."
				github_message forecast progress
				exit
			fi
		fi

	else
		echo "mom-${CYCLE_ID}-MOM (member $mem) failed, bailing out."
		touch ${POSTPROCESSING_LOGDIR}/MOM_${memstr}.failed
		github_message forecast fail
		exit
	fi
fi

if [ -f ${WDIR}/STOP ] || [ -f ${WDIR}/STOP_${memstr} ] ; then
    echo "STOP file detected, terminating"
    exit 0
fi


#====================================================================
if [ -f "${POSTPROCESSING_LOGDIR}/MOM_${memstr}.done" ]; then
	if [ ! -f "${POSTPROCESSING_LOGDIR}/NETCDF_COMBINE_${memstr}.done" ]; then
        	./merge.sh
	        if  stat -t *.nc.* >/dev/null 2>&1 ; then
        	        touch ${POSTPROCESSING_LOGDIR}/NETCDF_COMBINE_${memstr}.failed
			github_message merge_netcdf start
                	exit
	        else
        	        touch ${POSTPROCESSING_LOGDIR}/NETCDF_COMBINE_${memstr}.done
			github_message merge_netcdf success
        	fi
        fi
fi

if [ -f ${WDIR}/STOP ] || [ -f ${WDIR}/STOP_${memstr} ] ; then
    echo "STOP file detected, terminating"
    exit 0
fi


#====================================================================
# Launch Tarring scripts
if [ -f ${POSTPROCESSING_LOGDIR}/"NETCDF_COMBINE_${memstr}.done" ]; then
        if [ ! -f "${POSTPROCESSING_LOGDIR}/TARR_${memstr}.done" ]; then
		tar -cvf ${SAVE_EXP_DIR}/${memstr}.tar ${WDIR}/${memstr}
		touch ${POSTPROCESSING_LOGDIR}/TARR_${memstr}.done
		github_message tar_member success
	fi
fi

if [ -f ${WDIR}/STOP ] || [ -f ${WDIR}/STOP_${memstr} ] ; then
    echo "STOP file detected, terminating"
    exit 0
fi


#====================================================================
# Launch Regridding scripts
export PATH="${PYTHON}:${PYTHON}/bin:${PATH}"
export PYTHONPATH="${PYTHONPATH}:${ZARR_PATH}"
if [ -f ${POSTPROCESSING_LOGDIR}/"TARR_${memstr}.done" ]; then
        if [ ! -f "${POSTPROCESSING_LOGDIR}/REGRID_${memstr}.done" ]; then
		github_message regridding start
                ${POSTPROCESSING_SRCDIR}/convert_forecast_to_isobaric_Gadi.sh ./
                touch ${POSTPROCESSING_LOGDIR}/REGRID_${memstr}.done
		github_message regridding success

		#-------------------------------------------
		# NOTE: How can we detect if regrid failed?
		#-------------------------------------------
		# When we can, run the following to tell github
                # github_message regridding fail
		#-------------------------------------------
        fi
fi

if [ -f ${WDIR}/STOP ] || [ -f ${WDIR}/STOP_${memstr} ] ; then
    echo "STOP file detected, terminating"
    exit 0
fi


#====================================================================
# Set up striping of ZARR output directory
STRIPE_COUNT=60
if [ ! -d $ZARR_OUTPUT_PATH ]; then 
        mkdir $ZARR_OUTPUT_PATH
        lfs setstripe --stripe-count $STRIPE_COUNT --stripe-size 1M $ZARR_OUTPUT_PATH
elif (( `lfs getstripe -d $ZARR_OUTPUT_PATH | grep -oP "stripe_count:\s+\K[0-9]+"` != $STRIPE_COUNT )); then
        echo "$ZARR_OUTPUT_PATH exists but is not striped correctly"
        exit
fi

if [ -f ${WDIR}/STOP ] || [ -f ${WDIR}/STOP_${memstr} ] ; then
    echo "STOP file detected, terminating"
    exit 0
fi


#====================================================================
# Launch zarring scripts
OUTPUT_DIR=${ZARR_OUTPUT_PATH}/${memstr}
if [ -f "${POSTPROCESSING_LOGDIR}/REGRID_${memstr}.done" ]; then
        if [ ! -f "${POSTPROCESSING_LOGDIR}/ZARR_${memstr}.done" ]; then
		github_message zarring start

                cp -v ${POSTPROCESSING_SRCDIR}/$ZARR_CONFIG_FILE .

                # Create zarr collections on node local storage -----
                jobfs_path=${PBS_JOBFS}/ZARR
                python ${POSTPROCESSING_SRCDIR}/convert_forecast_to_zarr.py ${WDIR} ${jobfs_path} -r "all" -e $mem -c $ZARR_CONFIG_FILE --zip_output \
                    > ${POSTPROCESSING_LOGDIR}/ZARR_${memstr}.progress 2>&1

                # Copy zips to zarr_path -----
                echo "Copying collections to ${OUTPUT_DIR}..." >>${POSTPROCESSING_LOGDIR}/ZARR_${memstr}.progress
		STRIPE_COUNT=30
		if [ ! -d $OUTPUT_DIR ]; then
		        mkdir $OUTPUT_DIR
		        lfs setstripe --stripe-count $STRIPE_COUNT --stripe-size 1M $OUTPUT_DIR
		elif (( `lfs getstripe -d $OUTPUT_DIR | grep -oP "stripe_count:\s+\K[0-9]+"` != $STRIPE_COUNT )); then
		        echo "$OUTPUT_DIR exists but is not striped correctly"
		        exit
		fi
                cp ${jobfs_path}/*.zarr.zip $OUTPUT_DIR >>${POSTPROCESSING_LOGDIR}/ZARR_${memstr}.progress 2>&1
		
		chmod 775 $OUTPUT_DIR/*.zip

                touch ${POSTPROCESSING_LOGDIR}/ZARR_${memstr}.done
		github_message zarring success

		#-------------------------------------------
		# NOTE: How can we detect if ZARR failed?
		#-------------------------------------------
		# When we can, runt the following to tell github
                # github_message zarring fail
		#-------------------------------------------
        fi
fi

if [ -f ${WDIR}/STOP ] || [ -f ${WDIR}/STOP_${memstr} ] ; then
    echo "STOP file detected, terminating"
    exit 0
fi


#====================================================================
# Launch checking scripts
if [ -f "${POSTPROCESSING_LOGDIR}/ZARR_${memstr}.done" ]; then
        if [ ! -f "${POSTPROCESSING_LOGDIR}/CHECK_${memstr}.done" ]; then
		github_message error_checking start
                cp -v ${POSTPROCESSING_SRCDIR}/$CHECK_CONFIG_FILE .
                export PP_ZARR_PATH=$OUTPUT_DIR
                export PP_CONFIG_PATH=$CHECK_CONFIG_FILE
		pytest -v ${POSTPROCESSING_SRCDIR}/tests/test_zarr.py > ${POSTPROCESSING_LOGDIR}/CHECK_${memstr}.progress 2>&1
                status=$?
                if (( "$status" == "0" )); then
                	touch ${POSTPROCESSING_LOGDIR}/CHECK_${memstr}.done
			github_message error_checking success
		else
                	touch ${POSTPROCESSING_LOGDIR}/CHECK_${memstr}.failed
			github_message error_checking fail
                fi
        fi
fi

if [ -f ${WDIR}/STOP ] || [ -f ${WDIR}/STOP_${memstr} ] ; then
    echo "STOP file detected, terminating"
    exit 0
fi


#====================================================================
# Check if all zarring completed
num_complete=`ls ${POSTPROCESSING_LOGDIR}/CHECK_*.done | wc -l`
if (( num_complete == ENSSIZE )) ; then
        paths_to_merge=( `ls -d ${ZARR_OUTPUT_PATH}/mem???` )
        realms_as_separate_jobs=( atmos_daily atmos_isobaric_daily ocean_month ocean_bgc_month ) # all realms not specified here will be lumped into single additional job
        exclude_realms=( ) # realms not to merge (e.g. if already done)
        all_realms=$(python ${POSTPROCESSING_SRCDIR}/parse_realms.py < "$ZARR_CONFIG_FILE")
        remaining_realms=( `echo ${all_realms[@]} ${realms_as_separate_jobs[@]} ${exclude_realms[@]} | tr ' ' '\n' | sort | uniq -u` )
        cp -v ${POSTPROCESSING_SRCDIR}/merge_zarr_members.py .
        cp -v ${POSTPROCESSING_SRCDIR}/$CHECK_CONFIG_FILE .
        cp -v ${POSTPROCESSING_SRCDIR}/tests/test_zarr.py .
        n_merge_jobs=$((${#realms_as_separate_jobs[@]} + 1))
        for realm in ${realms_as_separate_jobs[@]}; do
                if [ ! -f "${POSTPROCESSING_LOGDIR}/MERGE_${realm}.done" ]; then
                        qsub -v "paths_to_merge=$(echo ${paths_to_merge[@]}), zarr_path=${ZARR_OUTPUT_PATH}, realms=$realm, n_merge_jobs=$n_merge_jobs, ZARR_CONFIG_FILE=$ZARR_CONFIG_FILE, CHECK_CONFIG_FILE=$CHECK_CONFIG_FILE, LOG_DIR=$POSTPROCESSING_LOGDIR" ${POSTPROCESSING_SRCDIR}/run_merge_members_Gadi.sh
                fi
        done
        if [ ! -f "${POSTPROCESSING_LOGDIR}/MERGE_${remaining_realms%% *}.done" ]; then
                qsub -v "paths_to_merge=$(echo ${paths_to_merge[@]}), zarr_path=${ZARR_OUTPUT_PATH}, realms=$(echo ${remaining_realms[@]}), n_merge_jobs=$n_merge_jobs, ZARR_CONFIG_FILE=$ZARR_CONFIG_FILE, CHECK_CONFIG_FILE=$CHECK_CONFIG_FILE, LOG_DIR=$POSTPROCESSING_LOGDIR" ${POSTPROCESSING_SRCDIR}/run_merge_members_Gadi.sh
        fi
	#-------------------------------------------
	# NOTE: How can we detect if merge realms failed??
	#-------------------------------------------


	# Once merging jobs tar up base file including the messaging logs
	tar -cvf ${SAVE_EXP_DIR}/logs.tar $WDIR/postprocessing_logs $WDIR/github_messages
	touch ${POSTPROCESSING_LOGDIR}/TARR_logs.done
	github_message tar_logs success
fi

#====================================================================
# EOF
#====================================================================
