# File: run_mom.sh.in
# Purpose: input for BASH script for running MOM5 models
# Author: Vassili Kitsios, modified from previous script of Pavel Sakov
# Date: 2020

set -euxEo pipefail
ulimit -c unlimited
export F_UFMTENDIAN=big

module list

WDIR=WDIR_INPUT
SAVE_EXP_DIR=SAVE_EXP_DIR_INPUT
CYCLE_ID=CYCLE_ID_INPUT
months=MONTHS_INPUT
mem=MEM1_INPUT
DT=DT_INPUT

PYTHON=PYTHON_INPUT
POSTPROCESSING_SRCDIR=POSTPROCESSING_SRCDIR_INPUT
ZARR_PATH=ZARR_PATH_INPUT
ZARR_CONFIG_FILE=zarr_specs_CAFE-f6.json
ZARR_OUTPUT_PATH=${SAVE_EXP_DIR}/ZARR
POSTPROCESSING_LOGDIR=${WDIR}/postprocessing_logs
GITHUB_MESSAGE_DIR=${WDIR}/github_messages
CHECK_CONFIG_FILE=check_specs.json

JULDAY=`cat ${WDIR}/JULDAY.txt | head -1`
EXPNAME=`basename ${WDIR}`
memstr=`printf "mem%03d" $mem`

# Make status logging directories
mkdir -p $GITHUB_MESSAGE_DIR
mkdir -p $POSTPROCESSING_LOGDIR


#====================================================================
# Small wrapper to make messaging simpler
github_message(){

        # Get user-provided stage and status information
        stage=$1
        status=$2

        # Execute
        python $POSTPROCESSING_SRCDIR/message.py \
        $GITHUB_MESSAGE_DIR \
        $EXPNAME/$memstr \
        $WDIR \
        $stage \
        $status

        # TODO: Provide a -m (message) option for errors?
}

cd ${WDIR}/$memstr

#====================================================================
# Check previous failures have been cleaned up
for prefix in MOM NETCDF_COMBINE CHECK; do
	if [ -f "${POSTPROCESSING_LOGDIR}/${prefix}_${memstr}.failed" ]; then
		echo Clean up $prefix for member $mem
		exit
	fi
done

#-------------------------------------------
# Need .failed files for REGRID_${memstr}, ZARR_${memstr}, MERGE_${realm}
#-------------------------------------------

for prefix in CHECK_MERGE; do
	if [ -f "${POSTPROCESSING_LOGDIR}/${prefix}.failed" ]; then
		echo Clean up $prefix
		exit
	fi
done

#====================================================================
if [ ! -f "${POSTPROCESSING_LOGDIR}/MOM_${memstr}.done" ]; then
	# Build namelist
	set +e
	rm -f input.nml
	cat ${WDIR}/MOM/input.nml \
		| sed "s/.*dt_ocean.*/dt_ocean = ${DT}/"\
	       	| sed "s/.*dt_cpld.*/dt_cpld = ${DT}/"\
	       	| sed "s/.*dt_atmos.*/dt_atmos = ${DT}/"\
		| sed "s/INPUT_MONTHS/months = ${months}/"\
	       	> input.nml

	# Launch MOM job
	github_message forecast start
	MOM_COMMAND_INPUT ./EXEC  2>&1 | tee mom-${DT}.out

	# Checck for successful completion
	set -e
        mom_complete_flag=`tail -n1 mom-${DT}.out | grep 'MPP_STACK high water mark=' | grep '0' | wc -l`
        if (( mom_complete_flag == 1 )) ; then
                echo "full success"

                # backup input files
                mkdir -p INPUT_SAVE
                files=`ls INPUT/*.res.nc*`
                for file in $files ; do
                        if [ -f "$file" ] ; then
                                mv $file INPUT_SAVE
                        fi
                done
                mv -f RESTART/* INPUT
                rm -f INPUT/????????.??0000.*.nc
                rm -f INPUT/????????.??0000.*.res

                touch ${POSTPROCESSING_LOGDIR}/MOM_${memstr}.done
		github_message forecast success

	else
		echo "mom-${CYCLE_ID}-MOM (member $mem) failed, bailing out"
		touch ${POSTPROCESSING_LOGDIR}/MOM_${memstr}.failed
		github_message forecast fail
		exit
	fi
fi

#====================================================================
if [ -f "${POSTPROCESSING_LOGDIR}/MOM_${memstr}.done" ]; then
	if [ ! -f "${POSTPROCESSING_LOGDIR}/NETCDF_COMBINE_${memstr}.done" ]; then
        	./merge.sh
	        if  stat -t *.nc.* >/dev/null 2>&1 ; then
        	        touch ${POSTPROCESSING_LOGDIR}/NETCDF_COMBINE_${memstr}.failed
			github_message merge_netcdf start
                	exit
	        else
        	        touch ${POSTPROCESSING_LOGDIR}/NETCDF_COMBINE_${memstr}.done
			github_message merge_netcdf success
        	fi
        fi
fi

#====================================================================
# Launch Regridding scripts
export PATH="${PYTHON}:${PYTHON}/bin:${PATH}"
export PYTHONPATH="${PYTHONPATH}:${ZARR_PATH}"
if [ -f ${POSTPROCESSING_LOGDIR}/"NETCDF_COMBINE_${memstr}.done" ]; then
        if [ ! -f "${POSTPROCESSING_LOGDIR}/REGRID_${memstr}.done" ]; then
		github_message regridding start
                ${POSTPROCESSING_SRCDIR}/convert_forecast_to_isobaric_Gadi.sh ./
                touch ${POSTPROCESSING_LOGDIR}/REGRID_${memstr}.done
		github_message regridding success

		#-------------------------------------------
		# How can we detect if regrid failed?
		#-------------------------------------------
		# When we can, run the following to tell github
                # github_message regridding fail
		#-------------------------------------------
        fi
fi

#====================================================================
# Set up striping of ZARR output directory
STRIPE_COUNT=60
if [ ! -d $ZARR_OUTPUT_PATH ]; then 
        mkdir $ZARR_OUTPUT_PATH
        lfs setstripe --stripe-count $STRIPE_COUNT --stripe-size 1M $ZARR_OUTPUT_PATH
elif (( `lfs getstripe -d $ZARR_OUTPUT_PATH | grep -oP "stripe_count:\s+\K[0-9]+"` != $STRIPE_COUNT )); then
        echo "$ZARR_OUTPUT_PATH exists but is not striped correctly"
        exit
fi

#====================================================================
# Launch zarring scripts
OUTPUT_DIR=${ZARR_OUTPUT_PATH}/${memstr}
if [ -f "${POSTPROCESSING_LOGDIR}/REGRID_${memstr}.done" ]; then
        if [ ! -f "${POSTPROCESSING_LOGDIR}/ZARR_${memstr}.done" ]; then
		github_message zarring start

                cp -v ${POSTPROCESSING_SRCDIR}/$ZARR_CONFIG_FILE .

                # Create zarr collections on node local storage -----
                jobfs_path=${PBS_JOBFS}/ZARR
                python ${POSTPROCESSING_SRCDIR}/convert_forecast_to_zarr.py ${WDIR} ${jobfs_path} -r "all" -e $mem -c $ZARR_CONFIG_FILE --zip_output \
                    > ${POSTPROCESSING_LOGDIR}/ZARR_${memstr}.progress 2>&1

                # Copy zips to zarr_path -----
                echo "Copying collections to ${OUTPUT_DIR}..." >>${POSTPROCESSING_LOGDIR}/ZARR_${memstr}.progress
		STRIPE_COUNT=30
		if [ ! -d $OUTPUT_DIR ]; then
		        mkdir $OUTPUT_DIR
		        lfs setstripe --stripe-count $STRIPE_COUNT --stripe-size 1M $OUTPUT_DIR
		elif (( `lfs getstripe -d $OUTPUT_DIR | grep -oP "stripe_count:\s+\K[0-9]+"` != $STRIPE_COUNT )); then
		        echo "$OUTPUT_DIR exists but is not striped correctly"
		        exit
		fi
                cp ${jobfs_path}/*.zarr.zip $OUTPUT_DIR >>${POSTPROCESSING_LOGDIR}/ZARR_${memstr}.progress 2>&1
		
		chmod 775 $OUTPUT_DIR/*.zip

                touch ${POSTPROCESSING_LOGDIR}/ZARR_${memstr}.done
		github_message zarring success

		#-------------------------------------------
		# How can we detect if ZARR failed?
		#-------------------------------------------
		# When we can, runt the following to tell github
                # github_message zarring fail
		#-------------------------------------------
        fi
fi


#====================================================================
# Launch checking scripts
if [ -f "${POSTPROCESSING_LOGDIR}/ZARR_${memstr}.done" ]; then
        if [ ! -f "${POSTPROCESSING_LOGDIR}/CHECK_${memstr}.done" ]; then
		github_message error_checking start
                cp -v ${POSTPROCESSING_SRCDIR}/$CHECK_CONFIG_FILE .
                export PP_ZARR_PATH=$OUTPUT_DIR
                export PP_CONFIG_PATH=$CHECK_CONFIG_FILE
		pytest -v ${POSTPROCESSING_SRCDIR}/tests/test_zarr.py > ${POSTPROCESSING_LOGDIR}/CHECK_${memstr}.progress 2>&1
                status=$?
                if (( "$status" == "0" )); then
                	touch ${POSTPROCESSING_LOGDIR}/CHECK_${memstr}.done
			github_message error_checking success
		else
                	touch ${POSTPROCESSING_LOGDIR}/CHECK_${memstr}.failed
			github_message error_checking fail
                fi
        fi
fi


#====================================================================
# Check if all zarring completed
num_complete=`ls ${POSTPROCESSING_LOGDIR}/CHECK_*.done | wc -l`
if (( num_complete == ENSSIZE )) ; then
        paths_to_merge=( `ls -d ${ZARR_OUTPUT_PATH}/mem???` )
        realms_as_separate_jobs=( atmos_daily atmos_isobaric_daily ocean_month ocean_bgc_month ) # all realms not specified here will be lumped into single additional job
        exclude_realms=( ) # realms not to merge (e.g. if already done)
        all_realms=$(python ${POSTPROCESSING_SRCDIR}/parse_realms.py < "$ZARR_CONFIG_FILE")
        remaining_realms=( `echo ${all_realms[@]} ${realms_as_separate_jobs[@]} ${exclude_realms[@]} | tr ' ' '\n' | sort | uniq -u` )
        cp -v ${POSTPROCESSING_SRCDIR}/merge_zarr_members.py .
        cp -v ${POSTPROCESSING_SRCDIR}/$CHECK_CONFIG_FILE .
        cp -v ${POSTPROCESSING_SRCDIR}/tests/test_zarr.py .
        n_merge_jobs=$((${#realms_as_separate_jobs[@]} + 1))
        for realm in ${realms_as_separate_jobs[@]}; do
                if [ ! -f "${POSTPROCESSING_LOGDIR}/MERGE_${realm}.done" ]; then
                        qsub -v "paths_to_merge=$(echo ${paths_to_merge[@]}), zarr_path=${ZARR_OUTPUT_PATH}, realms=$realm, n_merge_jobs=$n_merge_jobs, ZARR_CONFIG_FILE=$ZARR_CONFIG_FILE, CHECK_CONFIG_FILE=$CHECK_CONFIG_FILE, LOG_DIR=$POSTPROCESSING_LOGDIR" ${POSTPROCESSING_SRCDIR}/run_merge_members_Gadi.sh
                fi
        done
        if [ ! -f "${POSTPROCESSING_LOGDIR}/MERGE_${remaining_realms%% *}.done" ]; then
                qsub -v "paths_to_merge=$(echo ${paths_to_merge[@]}), zarr_path=${ZARR_OUTPUT_PATH}, realms=$(echo ${remaining_realms[@]}), n_merge_jobs=$n_merge_jobs, ZARR_CONFIG_FILE=$ZARR_CONFIG_FILE, CHECK_CONFIG_FILE=$CHECK_CONFIG_FILE, LOG_DIR=$POSTPROCESSING_LOGDIR" ${POSTPROCESSING_SRCDIR}/run_merge_members_Gadi.sh
        fi
	#-------------------------------------------
	# How can we detect if merge realms failed??
	#-------------------------------------------
fi

#====================================================================
# EOF
#====================================================================
